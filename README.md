# Microsoft Agent Framework - Single Agent Demo 
---

> **Note**: This is an updated implementation of the [Semantic Kernel Single Agent](https://github.com/lana-noor/sk-single-agent.git) repository, rebuilt using Microsoft Agent Framework. The core functionality remains the same, but this version leverages the newer unified framework for agent development.

## Overview

A conversational  AI agent built  with Microsoft Agent Framework of a knowledge agent with Azure OpenAI, Azure AI Search, and web search capabilities through a clean REST API and streaming interface.
This repository showcases a single-agent implementation using Microsoft Agent Framework, an open-source SDK for building, orchestrating, and deploying AI agents. The framework brings together ideas from Semantic Kernel and AutoGen projects, providing a unified foundation for creating AI agents with native tool integration, state management, and multi-turn conversation support.

The agent intelligently determines when to use each tool based on the user's query, seamlessly combining retrieval-augmented generation (RAG) with large language model capabilities.

The core of this solution is a single-agent AI assistant built with Microsoft Agent Framework that intelligently routes user queries to the most relevant data source using native Python function tools.
The agent in this demo is equipped with two native Python tools:
- Azure AI Search - Searches internal knowledge bases for organization-specific information
- Tavily Web Search - Retrieves current information from the web in real-time

### Architecture Workflow 
Microsoft Agent Framework AI Workflow Design: 
<img width="4800" height="2098" alt="REPO Microsoft Agent Framework Single Agent - ADIC Chatbot" src="https://github.com/user-attachments/assets/db27e19d-de5c-4cd4-a1d5-7290d6e640de" />

### Architecture highlights:
- User questions are ingested via a modern web UI (HTML/CSS/JavaScript frontend)
- The Agent Framework agent analyzes user intent and selects the appropriate tool
- Tools execute and return results to the agent
- The agent synthesizes responses using Azure OpenAI (GPT-4.1)
- Results are streamed back to the user in real-time with full conversation context

### Key Architectural Details
- Frontend: A standalone HTML/JavaScript chat interface with real-time streaming support via Server-Sent Events (SSE). The UI is modern, responsive, and requires no framework dependencies—just open frontend.html in a browser.
- Backend Orchestration: The core logic, chat flow, and agent orchestration are implemented in app_native_tools.py. The agent leverages Azure OpenAI Chat Completion (GPT-4) through Agent Framework's AzureOpenAIChatClient to analyze queries and select appropriate tools dynamically.
- Tools: Data source tools (Azure AI Search and Tavily web search) are implemented as native Python functions in the tools/ folder. These functions use type annotations and docstrings that the agent reads to understand when and how to invoke them—no complex MCP server setup required.
- Chat History: Conversation state is managed through Agent Framework's built-in threading system using AgentThread and ChatMessageStore. Each conversation maintains its own thread with persistent message history for multi-turn context.

## Microsoft Agent Framework FastAPI Application
The repo includes:
- **`app_native_tools.py`**: The backend is a FastAPI application that exposes the AI agent through REST endpoints with support for both traditional request-response and real-time streaming patterns.
  - AzureOpenAIChatClient: The core of the application uses Azure OpenAI through the Agent Framework's native client:
    
```
chat_client = AzureOpenAIChatClient(
    credential=AzureCliCredential(),  # Azure CLI authentication
    endpoint=AZURE_OPENAI_ENDPOINT,
    deployment_name=AZURE_OPENAI_DEPLOYMENT,
    api_version=AZURE_OPENAI_API_VERSION
)

agent = chat_client.create_agent(
    instructions=AZURE_OPENAI_PROMPT,
    tools=[search_documents, web_search]  # Native Python functions
)

```

API Endpoints: 
  - **`/api/chat`**: Traditional request-response endpoint that returns the complete agent response after processing.
    - Use case: Simple integrations, batch processing, or when real-time streaming isn't required.
  - **`/api/chat/stream`**: Streams agent responses in real-time as they're generated, providing a ChatGPT-like user experience. Leverages **`run_stream`**,  a method on the agent instance that returns an asynchronous iterator, providing streaming responses as they're generated by the mode
    - Use case: Interactive chat interfaces where users expect to see responses appear word-by-word.

---

## Deploy and Run 
### Prerequisites
- Python 3.8 or higher
- Azure OpenAI deployment (GPT-4 or GPT-4o recommended)
- Azure CLI installed and configured
- Azure AI Search service (optional, for document search)
- Tavily API key (optional, for web search)

  ### Set up the Application 

```bash
# Clone the repository and move to the root
cd agent_framework_single_agent

# Create and activate a virtual environment
python -m venv .venv
.\.venv\Scripts\Activate.ps1    # (on Windows PowerShell)

# Install required Python dependencies
pip install -r requirements.txt
pip install agent-framework --pre

# Log in to Azure with tenant ID 
az login --tenant "<tenant-id>"

```
### Run the Application 
1. Start the backend server
```bash
python app_native_tools.py
```
Output: 
```
============================================================
Agent Framework Chat API
============================================================
Azure OpenAI: https://your-resource.openai.azure.com/
Deployment: gpt-4.1

Native Tools:
  - AI Search (search_documents)
  - Tavily Web Search (web_search)
============================================================
Endpoints:
  POST /api/chat - Non-streaming
  POST /api/chat/stream - SSE streaming
============================================================
INFO:     Uvicorn running on http://0.0.0.0:8000
```
2. Open the frontend

Simply double-click frontend.html or open it in your browser. The frontend automatically connects to http://localhost:8000.

3. Start chatting!

Try these example queries:

"What is Azure OpenAI Service?"
"Search for information about AI readiness" (triggers Azure AI Search)
"What are the latest AI news headlines?" (triggers Tavily web search)

## API Reference 

| Method | Endpoint | Description |
|---|---|---|
| POST | `/api/chat` | Send message, get complete response |
| POST | `/api/chat/stream` | Send message, stream response via SSE |
| GET  | `/api/threads` | List all active conversation threads |
| GET  | `/api/history/{thread_id}` | Get conversation history for a thread |
| DELETE | `/api/thread/{thread_id}` | Delete a specific thread |
| POST | `/api/clear` | Clear all threads |
| GET  | `/health` | Health check endpoint |

## Request Format
```json
{
  "message": "Your question here",
  "thread_id": "optional-thread-id"
}
```

## Response Format (Non-streaming)
```json
{
  "response": "Agent's complete response",
  "thread_id": "thread_abc123"
}
```

## Response Format (Streaming)
```text
data: {"type": "start", "thread_id": "thread_abc123"}

data: {"type": "stream", "content": "Hello", "thread_id": "thread_abc123"}

data: {"type": "stream", "content": " there!", "thread_id": "thread_abc123"}

data: {"type": "end", "thread_id": "thread_abc123"}
```

```
